{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49d6b2d8",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install numpy --upgrade --only-binary :all:\n",
    "%pip install adversarial-robustness-toolbox torch torchvision pillow matplotlib opencv-python --only-binary :all:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec2e905",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc180e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.defences.trainer import AdversarialTrainer\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU detected: Using 20 epochs for thorough training\")\n",
    "    EPOCHS = 20\n",
    "else:\n",
    "    print(\"CPU detected: Using 10 epochs (training will be slower)\")\n",
    "    EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a89ca15",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Dataset\n",
    "\n",
    "We'll use STL-10 dataset which has higher resolution (96x96) images and includes classes like cars, trucks, airplanes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8712b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STL-10 preprocessing (96x96 images)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load STL-10 dataset (higher resolution: 96x96 vs CIFAR-10's 32x32)\n",
    "print(\"Downloading STL-10 dataset...\")\n",
    "train_dataset = torchvision.datasets.STL10(root='./data', split='train', download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.STL10(root='./data', split='test', download=True, transform=transform)\n",
    "\n",
    "# Use full training set for better accuracy (5000 samples)\n",
    "# STL-10 has 5000 training images and 8000 test images\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # Smaller batch due to larger images\n",
    "test_subset = Subset(test_dataset, range(1000))   # Use 1000 test samples\n",
    "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "# STL-10 class names\n",
    "class_names = ['airplane', 'bird', 'car', 'cat', 'deer', \n",
    "               'dog', 'horse', 'monkey', 'ship', 'truck']\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_subset)}\")\n",
    "print(f\"Image size: 96x96 (3x sharper than CIFAR-10)\")\n",
    "print(f\"Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b576e771",
   "metadata": {},
   "source": [
    "### Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8762dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some sample images\n",
    "def show_images(images, labels, title=\"Sample Images\", predictions=None):\n",
    "    # Ensure we don't try to display more images than available\n",
    "    num_images = min(10, len(images))\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        axes[i].imshow(img)\n",
    "        \n",
    "        if predictions is not None:\n",
    "            pred_label = class_names[predictions[i]]\n",
    "            true_label = class_names[labels[i]]\n",
    "            color = 'green' if predictions[i] == labels[i] else 'red'\n",
    "            axes[i].set_title(f\"True: {true_label}\\nPred: {pred_label}\", color=color, fontsize=9)\n",
    "        else:\n",
    "            axes[i].set_title(class_names[labels[i]], fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Hide unused subplots if we have fewer than 10 images\n",
    "    for i in range(num_images, 10):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "show_images(images, labels, \"STL-10 Sample Images (96x96)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c30122",
   "metadata": {},
   "source": [
    "## 4. Define a Simple CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # After 4 pooling layers: 96 -> 48 -> 24 -> 12 -> 6\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = self.pool(self.relu(self.conv4(x)))\n",
    "        x = x.view(-1, 256 * 6 * 6)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "print(\"CNN model defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa206ed",
   "metadata": {},
   "source": [
    "## 5. Train Standard Model (Without Adversarial Training)\n",
    "\n",
    "First, we'll train a standard model to establish a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caa0dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epochs=5):\n",
    "    \"\"\"Train a standard PyTorch model\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(f\"  Batch [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        epoch_acc = 100 * correct / total\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\\n\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and train standard model\n",
    "print(f\"Training standard model (no adversarial training) for {EPOCHS} epochs...\\n\")\n",
    "standard_model = SimpleCNN().to(device)\n",
    "standard_model = train_model(standard_model, train_loader, epochs=EPOCHS)\n",
    "print(\"Standard model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a5260",
   "metadata": {},
   "source": [
    "## 6. Evaluate Standard Model on Clean and Adversarial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddbe7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, attack=None, attack_name=\"Clean\"):\n",
    "    \"\"\"Evaluate model on test data\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.numpy()\n",
    "        labels_np = labels.numpy()\n",
    "        \n",
    "        # Generate adversarial examples if attack is provided\n",
    "        if attack is not None:\n",
    "            inputs = attack.generate(x=inputs)\n",
    "        \n",
    "        # Convert back to torch and evaluate\n",
    "        with torch.no_grad():\n",
    "            inputs_torch = torch.from_numpy(inputs).to(device)\n",
    "            outputs = model(inputs_torch)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += len(labels_np)\n",
    "        correct += (predicted.cpu().numpy() == labels_np).sum()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"{attack_name} Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Wrap model with ART classifier\n",
    "# Note: We need to provide an optimizer even though we're not training, \n",
    "# because PGD attack needs to compute gradients\n",
    "standard_classifier = PyTorchClassifier(\n",
    "    model=standard_model,\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    optimizer=optim.Adam(standard_model.parameters(), lr=0.001),\n",
    "    input_shape=(3, 96, 96),\n",
    "    nb_classes=10,\n",
    "    clip_values=(0, 1)\n",
    ")\n",
    "\n",
    "# Create PGD attack\n",
    "pgd_attack = ProjectedGradientDescent(\n",
    "    estimator=standard_classifier,\n",
    "    eps=0.03,\n",
    "    eps_step=0.01,\n",
    "    max_iter=10,\n",
    "    targeted=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== Standard Model Performance ===\")\n",
    "standard_clean_acc = evaluate_model(standard_model, test_loader, attack=None, attack_name=\"Clean\")\n",
    "standard_adv_acc = evaluate_model(standard_model, test_loader, attack=pgd_attack, attack_name=\"Adversarial (PGD)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca83815",
   "metadata": {},
   "source": [
    "### Visualize Standard Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d41d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch for visualization\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Clean predictions\n",
    "standard_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = standard_model(images.to(device))\n",
    "    _, clean_preds = torch.max(outputs, 1)\n",
    "\n",
    "# Adversarial predictions\n",
    "adv_images = pgd_attack.generate(x=images.numpy())\n",
    "with torch.no_grad():\n",
    "    outputs = standard_model(torch.from_numpy(adv_images).to(device))\n",
    "    _, adv_preds = torch.max(outputs, 1)\n",
    "\n",
    "# Display results\n",
    "print(\"Clean Images - Standard Model:\")\n",
    "show_images(images, labels, \"Standard Model: Clean Images\", clean_preds.cpu().numpy())\n",
    "\n",
    "print(\"\\nAdversarial Images - Standard Model:\")\n",
    "show_images(torch.from_numpy(adv_images), labels, \"Standard Model: Adversarial Images (PGD)\", adv_preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ab3e97",
   "metadata": {},
   "source": [
    "## 7. Adversarial Training\n",
    "\n",
    "Now we'll train a model using adversarial training - training on both clean and adversarial examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a2814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model for adversarial training\n",
    "robust_model = SimpleCNN().to(device)\n",
    "\n",
    "# Wrap with ART classifier\n",
    "robust_classifier = PyTorchClassifier(\n",
    "    model=robust_model,\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    optimizer=optim.Adam(robust_model.parameters(), lr=0.001),\n",
    "    input_shape=(3, 96, 96),\n",
    "    nb_classes=10,\n",
    "    clip_values=(0, 1)\n",
    ")\n",
    "\n",
    "# Create adversarial trainer\n",
    "pgd_attack_train = ProjectedGradientDescent(\n",
    "    estimator=robust_classifier,\n",
    "    eps=0.03,\n",
    "    eps_step=0.01,\n",
    "    max_iter=10,\n",
    "    targeted=False\n",
    ")\n",
    "\n",
    "trainer = AdversarialTrainer(robust_classifier, attacks=pgd_attack_train, ratio=0.5)\n",
    "\n",
    "print(\"Starting adversarial training...\\n\")\n",
    "print(\"This trains the model on a mix of clean (50%) and adversarial (50%) examples.\\n\")\n",
    "\n",
    "# Prepare data for ART\n",
    "X_train = []\n",
    "y_train = []\n",
    "for images, labels in train_loader:\n",
    "    X_train.append(images.numpy())\n",
    "    y_train.append(labels.numpy())\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=0)\n",
    "y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "# Perform adversarial training\n",
    "print(f\"Training for {EPOCHS} epochs...\")\n",
    "trainer.fit(X_train, y_train, nb_epochs=EPOCHS, batch_size=32)\n",
    "\n",
    "print(\"\\nAdversarial training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c1aa78",
   "metadata": {},
   "source": [
    "## 8. Evaluate Robust Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7452e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the attack to use the robust classifier\n",
    "pgd_attack_robust = ProjectedGradientDescent(\n",
    "    estimator=robust_classifier,\n",
    "    eps=0.03,\n",
    "    eps_step=0.01,\n",
    "    max_iter=10,\n",
    "    targeted=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== Robust Model Performance (After Adversarial Training) ===\")\n",
    "robust_clean_acc = evaluate_model(robust_model, test_loader, attack=None, attack_name=\"Clean\")\n",
    "robust_adv_acc = evaluate_model(robust_model, test_loader, attack=pgd_attack_robust, attack_name=\"Adversarial (PGD)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e5fd6a",
   "metadata": {},
   "source": [
    "### Visualize Robust Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same batch from earlier\n",
    "# Clean predictions\n",
    "robust_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = robust_model(images.to(device))\n",
    "    _, clean_preds_robust = torch.max(outputs, 1)\n",
    "\n",
    "# Adversarial predictions\n",
    "adv_images_robust = pgd_attack_robust.generate(x=images.numpy())\n",
    "with torch.no_grad():\n",
    "    outputs = robust_model(torch.from_numpy(adv_images_robust).to(device))\n",
    "    _, adv_preds_robust = torch.max(outputs, 1)\n",
    "\n",
    "# Display results\n",
    "print(\"Clean Images - Robust Model:\")\n",
    "show_images(images, labels, \"Robust Model: Clean Images\", clean_preds_robust.cpu().numpy())\n",
    "\n",
    "print(\"\\nAdversarial Images - Robust Model:\")\n",
    "show_images(torch.from_numpy(adv_images_robust), labels, \"Robust Model: Adversarial Images (PGD)\", adv_preds_robust.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec92ec4",
   "metadata": {},
   "source": [
    "## 9. Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25401eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison chart\n",
    "models = ['Standard Model', 'Robust Model']\n",
    "clean_accuracies = [standard_clean_acc, robust_clean_acc]\n",
    "adv_accuracies = [standard_adv_acc, robust_adv_acc]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(x - width/2, clean_accuracies, width, label='Clean Accuracy', color='skyblue')\n",
    "bars2 = ax.bar(x + width/2, adv_accuracies, width, label='Adversarial Accuracy', color='salmon')\n",
    "\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models, fontsize=11)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "def add_value_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}%',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "add_value_labels(bars1)\n",
    "add_value_labels(bars2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print improvement\n",
    "improvement = robust_adv_acc - standard_adv_acc\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"ADVERSARIAL ROBUSTNESS IMPROVEMENT: +{improvement:.2f}%\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"\\nStandard Model:\")\n",
    "print(f\"  - Clean Accuracy: {standard_clean_acc:.2f}%\")\n",
    "print(f\"  - Adversarial Accuracy: {standard_adv_acc:.2f}%\")\n",
    "print(f\"  - Robustness Gap: {standard_clean_acc - standard_adv_acc:.2f}%\")\n",
    "print(f\"\\nRobust Model (Adversarial Training):\")\n",
    "print(f\"  - Clean Accuracy: {robust_clean_acc:.2f}%\")\n",
    "print(f\"  - Adversarial Accuracy: {robust_adv_acc:.2f}%\")\n",
    "print(f\"  - Robustness Gap: {robust_clean_acc - robust_adv_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da7ef2",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Standard Model Vulnerability**:\n",
    "   - High accuracy on clean images\n",
    "   - Significant drop in accuracy on adversarial examples\n",
    "   - Vulnerable to PGD attacks\n",
    "\n",
    "2. **Adversarial Training Defense**:\n",
    "   - Trains on both clean and adversarial examples\n",
    "   - Significantly improves robustness against attacks\n",
    "   - May slightly reduce clean accuracy but greatly improves adversarial accuracy\n",
    "\n",
    "3. **Trade-offs**:\n",
    "   - Adversarial training takes longer (generating adversarial examples during training)\n",
    "   - Small potential decrease in clean accuracy\n",
    "   - Large improvement in adversarial robustness\n",
    "\n",
    "### Automotive AI Applications:\n",
    "\n",
    "- **Critical for Safety**: Autonomous vehicles must be robust against adversarial perturbations\n",
    "- **Real-world Attacks**: Physical adversarial patches could fool perception systems\n",
    "- **Defense Strategy**: Adversarial training is one of the most effective defenses\n",
    "- **Continuous Improvement**: Models should be regularly updated with new attack patterns\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Experiment with different attack strengths (eps values)\n",
    "- Try different attack methods (FGSM, C&W, etc.)\n",
    "- Combine with other defense mechanisms\n",
    "- Test on domain-specific automotive datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
