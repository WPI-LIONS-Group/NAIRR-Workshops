{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19937c0f",
   "metadata": {},
   "source": [
    "# AI Car Detection - Dashcam Video Simulation\n",
    "\n",
    "This notebook demonstrates object detection on a dashcam video, focusing on detecting cars and vehicles using a pre-trained YOLO model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f9177",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (using pre-built wheels to avoid compilation)\n",
    "%pip install --upgrade pip\n",
    "%pip install numpy --upgrade --only-binary :all:\n",
    "%pip install opencv-python-headless matplotlib IPython requests --only-binary :all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, display, Video\n",
    "from base64 import b64encode\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f8b7b0",
   "metadata": {},
   "source": [
    "## 2. Download and Load Pre-trained YOLO Model\n",
    "\n",
    "We'll use YOLOv3 (You Only Look Once) which is excellent for real-time object detection including cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8580f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model files if they don't exist\n",
    "import urllib.request\n",
    "\n",
    "def download_file(url, destination, description=\"file\"):\n",
    "    \"\"\"Download a file if it doesn't already exist.\"\"\"\n",
    "    if os.path.exists(destination):\n",
    "        print(f\"✓ {description} already exists\")\n",
    "        return True\n",
    "    \n",
    "    print(f\"Downloading {description}...\")\n",
    "    os.makedirs(os.path.dirname(destination), exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        def show_progress(block_num, block_size, total_size):\n",
    "            downloaded = block_num * block_size\n",
    "            if total_size > 0:\n",
    "                percent = min(downloaded * 100.0 / total_size, 100.0)\n",
    "                mb_downloaded = downloaded / (1024 * 1024)\n",
    "                mb_total = total_size / (1024 * 1024)\n",
    "                print(f\"\\rProgress: {percent:.1f}% ({mb_downloaded:.1f}/{mb_total:.1f} MB)\", end='')\n",
    "        \n",
    "        urllib.request.urlretrieve(url, destination, show_progress)\n",
    "        print(f\"\\n✓ Downloaded {description}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Download YOLOv3 model files\n",
    "print(\"Checking model files...\\n\")\n",
    "\n",
    "files = [\n",
    "    (\"https://pjreddie.com/media/files/yolov3.weights\", \n",
    "     \"models/yolov3.weights\", \"YOLOv3 weights (237 MB)\"),\n",
    "    (\"https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\", \n",
    "     \"models/yolov3.cfg\", \"YOLOv3 config\"),\n",
    "    (\"https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\", \n",
    "     \"models/coco.names\", \"COCO class names\")\n",
    "]\n",
    "\n",
    "for url, dest, desc in files:\n",
    "    download_file(url, dest, desc)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model\n",
    "print(\"\\nLoading YOLO model...\")\n",
    "net = cv2.dnn.readNet(\"models/yolov3.weights\", \"models/yolov3.cfg\")\n",
    "\n",
    "# Load class names\n",
    "with open(\"models/coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Get output layer names\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "print(f\"✓ YOLO model loaded successfully!\")\n",
    "print(f\"Total classes: {len(classes)}\")\n",
    "print(f\"Vehicle-related classes: car, truck, bus, motorbike\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a62e5d",
   "metadata": {},
   "source": [
    "## 3. Load Dashcam Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe2539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dashcam video\n",
    "video_path = \"videos/dash_cam.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"Video loaded: {video_path}\")\n",
    "print(f\"Resolution: {width}x{height}\")\n",
    "print(f\"FPS: {fps}\")\n",
    "print(f\"Total frames: {total_frames}\")\n",
    "print(f\"Duration: {total_frames/fps:.2f} seconds\")\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bba6f78",
   "metadata": {},
   "source": [
    "## 4. Define Car Detection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6964219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(frame):\n",
    "    \"\"\"Detect objects in a frame using YOLO\"\"\"\n",
    "    height, width = frame.shape[:2]\n",
    "    \n",
    "    # Prepare image for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(output_layers)\n",
    "    \n",
    "    # Process detections\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    \n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            # Filter for vehicles with confidence > 0.5\n",
    "            if confidence > 0.5 and classes[class_id] in ['car', 'truck', 'bus', 'motorbike']:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "                \n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    \n",
    "    # Apply non-maximum suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    \n",
    "    # Draw boxes\n",
    "    detected_count = 0\n",
    "    if len(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = f\"{classes[class_ids[i]]}: {confidences[i]:.2f}\"\n",
    "            color = (0, 255, 0)  # Green for vehicles\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "            detected_count += 1\n",
    "    \n",
    "    return frame, detected_count\n",
    "\n",
    "print(\"Detection function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf110aed",
   "metadata": {},
   "source": [
    "## 5. Process Video and Detect Cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Output video writer\n",
    "output_path = \"videos/detected_output.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "frame_count = 0\n",
    "total_detections = 0\n",
    "\n",
    "print(\"Processing video frames...\")\n",
    "print(\"This may take a few minutes depending on video length...\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Detect objects in frame\n",
    "    processed_frame, detections = detect_objects(frame)\n",
    "    total_detections += detections\n",
    "    \n",
    "    # Write processed frame\n",
    "    out.write(processed_frame)\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % 30 == 0:  # Progress update every 30 frames\n",
    "        print(f\"Processed {frame_count}/{total_frames} frames...\")\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"\\n✓ Processing complete!\")\n",
    "print(f\"Total frames processed: {frame_count}\")\n",
    "print(f\"Average vehicles per frame: {total_detections/frame_count:.2f}\")\n",
    "print(f\"Output saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d18bdb2",
   "metadata": {},
   "source": [
    "## 6. Display Sample Detection Results\n",
    "\n",
    "Let's display a few sample frames to see the detection results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e546f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample frames from processed video\n",
    "cap = cv2.VideoCapture(output_path)\n",
    "\n",
    "# Get frames at different timestamps\n",
    "sample_positions = [0.2, 0.4, 0.6, 0.8]  # 20%, 40%, 60%, 80% through video\n",
    "sample_frames = []\n",
    "\n",
    "for pos in sample_positions:\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, int(total_frames * pos))\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Convert BGR to RGB for matplotlib\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        sample_frames.append(frame_rgb)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Display frames\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Car Detection Results - Sample Frames', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (ax, frame) in enumerate(zip(axes.flat, sample_frames)):\n",
    "    ax.imshow(frame)\n",
    "    ax.set_title(f'Frame at {int(sample_positions[idx]*100)}%', fontsize=12)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Sample frames displayed above with detected vehicles highlighted in green boxes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
